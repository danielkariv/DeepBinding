Run with Hyperparams:
Number of Seqs: 15000, Batch_size: 64, Number of Epochs: 30, Learning Rate: 0.001, Weight Decay: 1e-05, Betas: (0.9, 0.999)
Load Data!
Loaded seqs file:  RBNS_training/RBP1_input.seq
Loaded seqs file:  RBNS_training/RBP1_5nM.seq
Loaded seqs file:  RBNS_training/RBP1_20nM.seq
Loaded seqs file:  RBNS_training/RBP1_80nM.seq
Loaded seqs file:  RBNS_training/RBP1_320nM.seq
Loaded seqs file:  RBNS_training/RBP1_1300nM.seq
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 512, 37]          16,896
              ReLU-2              [-1, 512, 37]               0
         MaxPool1d-3               [-1, 512, 7]               0
            Linear-4                   [-1, 64]         229,440
              ReLU-5                   [-1, 64]               0
           Dropout-6                   [-1, 64]               0
            Linear-7                   [-1, 32]           2,080
              ReLU-8                   [-1, 32]               0
           Dropout-9                   [-1, 32]               0
           Linear-10                   [-1, 32]           1,056
             ReLU-11                   [-1, 32]               0
          Dropout-12                   [-1, 32]               0
           Linear-13                    [-1, 6]             198
          Sigmoid-14                    [-1, 6]               0
================================================================
Total params: 249,670
Trainable params: 249,670
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.95
Estimated Total Size (MB): 1.27
----------------------------------------------------------------
Start Training!
Epoch [1/30]
Loss: 0.35836157841152616, Patience [0/3] (Best Loss: 0.35836157841152616)
Epoch [2/30]
Loss: 0.3583587373521593, Patience [0/3] (Best Loss: 0.3583587373521593)
Epoch [3/30]
Loss: 0.35835523698594834, Patience [0/3] (Best Loss: 0.35835523698594834)
Epoch [4/30]
Loss: 0.35836211827596026, Patience [1/3] (Best Loss: 0.35835523698594834)
Epoch [5/30]
Loss: 0.35835953958299427, Patience [2/3] (Best Loss: 0.35835523698594834)
Epoch [6/30]
Loss: 0.3583728107876248, Patience [3/3] (Best Loss: 0.35835523698594834)
Early stopping! Validation loss didn't improve in the last 3 epochs.
Start evaluate! Combination=(0, 2, 3, 4, 5)
Pearson correlation: -8.049221844608212e-10
Elapsed Time: 184.26601815223694 seconds
Run with Hyperparams:
Number of Seqs: 15000, Batch_size: 64, Number of Epochs: 30, Learning Rate: 0.001, Weight Decay: 1e-05, Betas: (0.9, 0.999)
Load Data!
Loaded seqs file:  RBNS_training/RBP2_input.seq
Loaded seqs file:  RBNS_training/RBP2_5nM.seq
Loaded seqs file:  RBNS_training/RBP2_20nM.seq
Loaded seqs file:  RBNS_training/RBP2_80nM.seq
Loaded seqs file:  RBNS_training/RBP2_320nM.seq
Loaded seqs file:  RBNS_training/RBP2_1300nM.seq
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 512, 37]          16,896
              ReLU-2              [-1, 512, 37]               0
         MaxPool1d-3               [-1, 512, 7]               0
            Linear-4                   [-1, 64]         229,440
              ReLU-5                   [-1, 64]               0
           Dropout-6                   [-1, 64]               0
            Linear-7                   [-1, 32]           2,080
              ReLU-8                   [-1, 32]               0
           Dropout-9                   [-1, 32]               0
           Linear-10                   [-1, 32]           1,056
             ReLU-11                   [-1, 32]               0
          Dropout-12                   [-1, 32]               0
           Linear-13                    [-1, 6]             198
          Sigmoid-14                    [-1, 6]               0
================================================================
Total params: 249,670
Trainable params: 249,670
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.95
Estimated Total Size (MB): 1.27
----------------------------------------------------------------
Start Training!
Epoch [1/30]
Loss: 0.3573270608054267, Patience [0/3] (Best Loss: 0.3573270608054267)
Epoch [2/30]
Loss: 0.3557805087619358, Patience [0/3] (Best Loss: 0.3557805087619358)
Epoch [3/30]
Loss: 0.3549066298590766, Patience [0/3] (Best Loss: 0.3549066298590766)
Epoch [4/30]
Loss: 0.35434135695563423, Patience [0/3] (Best Loss: 0.35434135695563423)
Epoch [5/30]
Loss: 0.35413306100633407, Patience [0/3] (Best Loss: 0.35413306100633407)
Epoch [6/30]
Loss: 0.3540300459967719, Patience [0/3] (Best Loss: 0.3540300459967719)
Epoch [7/30]
Loss: 0.35366950872209335, Patience [0/3] (Best Loss: 0.35366950872209335)
Epoch [8/30]
Loss: 0.35363773074679905, Patience [0/3] (Best Loss: 0.35363773074679905)
Epoch [9/30]
Loss: 0.3535041772418552, Patience [0/3] (Best Loss: 0.3535041772418552)
Epoch [10/30]
Loss: 0.35352059177822537, Patience [1/3] (Best Loss: 0.3535041772418552)
Epoch [11/30]
Loss: 0.3540269182417128, Patience [2/3] (Best Loss: 0.3535041772418552)
Epoch [12/30]
Loss: 0.3535005472607083, Patience [0/3] (Best Loss: 0.3535005472607083)
Epoch [13/30]
Loss: 0.35424455846150715, Patience [1/3] (Best Loss: 0.3535005472607083)
Epoch [14/30]
Loss: 0.35356212143368193, Patience [2/3] (Best Loss: 0.3535005472607083)
Epoch [15/30]
Loss: 0.35381172398461236, Patience [3/3] (Best Loss: 0.3535005472607083)
Early stopping! Validation loss didn't improve in the last 3 epochs.
Start evaluate! Combination=(0, 2, 3, 4, 5)
Pearson correlation: 0.25616076588630676
Elapsed Time: 365.91420555114746 seconds
Run with Hyperparams:
Number of Seqs: 15000, Batch_size: 64, Number of Epochs: 30, Learning Rate: 0.001, Weight Decay: 1e-05, Betas: (0.9, 0.999)
Load Data!
Loaded seqs file:  RBNS_training/RBP3_input.seq
Loaded seqs file:  RBNS_training/RBP3_5nM.seq
Loaded seqs file:  RBNS_training/RBP3_20nM.seq
Loaded seqs file:  RBNS_training/RBP3_80nM.seq
Loaded seqs file:  RBNS_training/RBP3_320nM.seq
Loaded seqs file:  RBNS_training/RBP3_1300nM.seq
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 512, 37]          16,896
              ReLU-2              [-1, 512, 37]               0
         MaxPool1d-3               [-1, 512, 7]               0
            Linear-4                   [-1, 64]         229,440
              ReLU-5                   [-1, 64]               0
           Dropout-6                   [-1, 64]               0
            Linear-7                   [-1, 32]           2,080
              ReLU-8                   [-1, 32]               0
           Dropout-9                   [-1, 32]               0
           Linear-10                   [-1, 32]           1,056
             ReLU-11                   [-1, 32]               0
          Dropout-12                   [-1, 32]               0
           Linear-13                    [-1, 6]             198
          Sigmoid-14                    [-1, 6]               0
================================================================
Total params: 249,670
Trainable params: 249,670
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.95
Estimated Total Size (MB): 1.27
----------------------------------------------------------------
Start Training!
Epoch [1/30]
Loss: 0.3583778813680013, Patience [0/3] (Best Loss: 0.3583778813680013)
Epoch [2/30]
Loss: 0.3583973057852851, Patience [1/3] (Best Loss: 0.3583778813680013)
Epoch [3/30]
Loss: 0.35837460481855604, Patience [0/3] (Best Loss: 0.35837460481855604)
Epoch [4/30]
Loss: 0.35838360150655113, Patience [1/3] (Best Loss: 0.35837460481855604)
Epoch [5/30]
Loss: 0.3584038663864136, Patience [2/3] (Best Loss: 0.35837460481855604)
Epoch [6/30]
Loss: 0.3584009225209554, Patience [3/3] (Best Loss: 0.35837460481855604)
Early stopping! Validation loss didn't improve in the last 3 epochs.
Start evaluate! Combination=(0, 2, 3, 4, 5)
Pearson correlation: 0.04411177709698677
Elapsed Time: 181.89409494400024 seconds
Run with Hyperparams:
Number of Seqs: 15000, Batch_size: 64, Number of Epochs: 30, Learning Rate: 0.001, Weight Decay: 1e-05, Betas: (0.9, 0.999)
Load Data!
Loaded seqs file:  RBNS_training/RBP4_input.seq
Loaded seqs file:  RBNS_training/RBP4_5nM.seq
Loaded seqs file:  RBNS_training/RBP4_20nM.seq
Loaded seqs file:  RBNS_training/RBP4_80nM.seq
Loaded seqs file:  RBNS_training/RBP4_320nM.seq
Loaded seqs file:  RBNS_training/RBP4_1300nM.seq
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 512, 37]          16,896
              ReLU-2              [-1, 512, 37]               0
         MaxPool1d-3               [-1, 512, 7]               0
            Linear-4                   [-1, 64]         229,440
              ReLU-5                   [-1, 64]               0
           Dropout-6                   [-1, 64]               0
            Linear-7                   [-1, 32]           2,080
              ReLU-8                   [-1, 32]               0
           Dropout-9                   [-1, 32]               0
           Linear-10                   [-1, 32]           1,056
             ReLU-11                   [-1, 32]               0
          Dropout-12                   [-1, 32]               0
           Linear-13                    [-1, 6]             198
          Sigmoid-14                    [-1, 6]               0
================================================================
Total params: 249,670
Trainable params: 249,670
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.95
Estimated Total Size (MB): 1.27
----------------------------------------------------------------
Start Training!
Epoch [1/30]
Loss: 0.3583683530595568, Patience [0/3] (Best Loss: 0.3583683530595568)
Epoch [2/30]
Loss: 0.3583824543846978, Patience [1/3] (Best Loss: 0.3583683530595568)
Epoch [3/30]
Loss: 0.3583600669225057, Patience [0/3] (Best Loss: 0.3583600669225057)
Epoch [4/30]
Loss: 0.35836197018093535, Patience [1/3] (Best Loss: 0.3583600669225057)
Epoch [5/30]
Loss: 0.35837465137905544, Patience [2/3] (Best Loss: 0.3583600669225057)
Epoch [6/30]
Loss: 0.3583642739613851, Patience [3/3] (Best Loss: 0.3583600669225057)
Early stopping! Validation loss didn't improve in the last 3 epochs.
Start evaluate! Combination=(0, 2, 3, 4, 5)
Pearson correlation: -4.714014067985772e-09
Elapsed Time: 179.18266987800598 seconds
Run with Hyperparams:
Number of Seqs: 15000, Batch_size: 64, Number of Epochs: 30, Learning Rate: 0.001, Weight Decay: 1e-05, Betas: (0.9, 0.999)
Load Data!
Loaded seqs file:  RBNS_training/RBP5_input.seq
Loaded seqs file:  RBNS_training/RBP5_5nM.seq
Loaded seqs file:  RBNS_training/RBP5_20nM.seq
Loaded seqs file:  RBNS_training/RBP5_80nM.seq
Loaded seqs file:  RBNS_training/RBP5_320nM.seq
Loaded seqs file:  RBNS_training/RBP5_1300nM.seq
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 512, 37]          16,896
              ReLU-2              [-1, 512, 37]               0
         MaxPool1d-3               [-1, 512, 7]               0
            Linear-4                   [-1, 64]         229,440
              ReLU-5                   [-1, 64]               0
           Dropout-6                   [-1, 64]               0
            Linear-7                   [-1, 32]           2,080
              ReLU-8                   [-1, 32]               0
           Dropout-9                   [-1, 32]               0
           Linear-10                   [-1, 32]           1,056
             ReLU-11                   [-1, 32]               0
          Dropout-12                   [-1, 32]               0
           Linear-13                    [-1, 6]             198
          Sigmoid-14                    [-1, 6]               0
================================================================
Total params: 249,670
Trainable params: 249,670
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.95
Estimated Total Size (MB): 1.27
----------------------------------------------------------------
Start Training!
Epoch [1/30]
Loss: 0.35835475832621255, Patience [0/3] (Best Loss: 0.35835475832621255)
Epoch [2/30]
Loss: 0.35835913132561575, Patience [1/3] (Best Loss: 0.35835475832621255)
Epoch [3/30]
Loss: 0.3583555090162489, Patience [2/3] (Best Loss: 0.35835475832621255)
Epoch [4/30]
Loss: 0.35836275329589845, Patience [3/3] (Best Loss: 0.35835475832621255)
Early stopping! Validation loss didn't improve in the last 3 epochs.
Start evaluate! Combination=(0, 2, 3, 4, 5)
Pearson correlation: 4.2279886258711485e-08
Elapsed Time: 166.7718768119812 seconds
Run with Hyperparams:
Number of Seqs: 15000, Batch_size: 64, Number of Epochs: 30, Learning Rate: 0.001, Weight Decay: 1e-05, Betas: (0.9, 0.999)
Load Data!
Loaded seqs file:  RBNS_training/RBP6_input.seq
Loaded seqs file:  RBNS_training/RBP6_5nM.seq
Loaded seqs file:  RBNS_training/RBP6_20nM.seq
Loaded seqs file:  RBNS_training/RBP6_80nM.seq
Loaded seqs file:  RBNS_training/RBP6_320nM.seq
Loaded seqs file:  RBNS_training/RBP6_1300nM.seq
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 512, 37]          16,896
              ReLU-2              [-1, 512, 37]               0
         MaxPool1d-3               [-1, 512, 7]               0
            Linear-4                   [-1, 64]         229,440
              ReLU-5                   [-1, 64]               0
           Dropout-6                   [-1, 64]               0
            Linear-7                   [-1, 32]           2,080
              ReLU-8                   [-1, 32]               0
           Dropout-9                   [-1, 32]               0
           Linear-10                   [-1, 32]           1,056
             ReLU-11                   [-1, 32]               0
          Dropout-12                   [-1, 32]               0
           Linear-13                    [-1, 6]             198
          Sigmoid-14                    [-1, 6]               0
================================================================
Total params: 249,670
Trainable params: 249,670
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.95
Estimated Total Size (MB): 1.27
----------------------------------------------------------------
Start Training!
Epoch [1/30]
Loss: 0.3583646596696642, Patience [0/3] (Best Loss: 0.3583646596696642)
Epoch [2/30]
Loss: 0.35836173559824624, Patience [0/3] (Best Loss: 0.35836173559824624)
Epoch [3/30]
Loss: 0.3583607165442573, Patience [0/3] (Best Loss: 0.3583607165442573)
Epoch [4/30]
Loss: 0.35836471672058107, Patience [1/3] (Best Loss: 0.3583607165442573)
Epoch [5/30]
Loss: 0.3583595903608534, Patience [0/3] (Best Loss: 0.3583595903608534)
Epoch [6/30]
Loss: 0.3583577697330051, Patience [0/3] (Best Loss: 0.3583577697330051)
Epoch [7/30]
Loss: 0.35835882523854573, Patience [1/3] (Best Loss: 0.3583577697330051)
Epoch [8/30]
Loss: 0.3583547385957506, Patience [0/3] (Best Loss: 0.3583547385957506)
Epoch [9/30]
Loss: 0.35835549087524415, Patience [1/3] (Best Loss: 0.3583547385957506)
Epoch [10/30]
Loss: 0.35835626742045085, Patience [2/3] (Best Loss: 0.3583547385957506)
Epoch [11/30]
Loss: 0.3583600723054674, Patience [3/3] (Best Loss: 0.3583547385957506)
Early stopping! Validation loss didn't improve in the last 3 epochs.
Start evaluate! Combination=(0, 2, 3, 4, 5)
Pearson correlation: 0.014183035120368004
Elapsed Time: 268.03231477737427 seconds
Run with Hyperparams:
Number of Seqs: 15000, Batch_size: 64, Number of Epochs: 30, Learning Rate: 0.001, Weight Decay: 1e-05, Betas: (0.9, 0.999)
Load Data!
Loaded seqs file:  RBNS_training/RBP7_input.seq
Loaded seqs file:  RBNS_training/RBP7_5nM.seq
Loaded seqs file:  RBNS_training/RBP7_20nM.seq
Loaded seqs file:  RBNS_training/RBP7_80nM.seq
Loaded seqs file:  RBNS_training/RBP7_320nM.seq
Loaded seqs file:  RBNS_training/RBP7_1300nM.seq
----------------------------------------------------------------
        Layer (type)               Output Shape         Param # 
================================================================
            Conv1d-1              [-1, 512, 37]          16,896 
              ReLU-2              [-1, 512, 37]               0 
         MaxPool1d-3               [-1, 512, 7]               0
            Linear-4                   [-1, 64]         229,440
              ReLU-5                   [-1, 64]               0
           Dropout-6                   [-1, 64]               0
            Linear-7                   [-1, 32]           2,080
              ReLU-8                   [-1, 32]               0
           Dropout-9                   [-1, 32]               0
           Linear-10                   [-1, 32]           1,056
             ReLU-11                   [-1, 32]               0
          Dropout-12                   [-1, 32]               0
           Linear-13                    [-1, 6]             198
          Sigmoid-14                    [-1, 6]               0
================================================================
Total params: 249,670
Trainable params: 249,670
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.95
Estimated Total Size (MB): 1.27
----------------------------------------------------------------
Start Training!
Epoch [1/30]
Loss: 0.35835673033396404, Patience [0/3] (Best Loss: 0.35835673033396404)
Epoch [2/30]
Loss: 0.358358324707879, Patience [1/3] (Best Loss: 0.35835673033396404)
Epoch [3/30]
Loss: 0.35835332658555774, Patience [0/3] (Best Loss: 0.35835332658555774)
Epoch [4/30]
Loss: 0.3583543242984348, Patience [1/3] (Best Loss: 0.35835332658555774)
Epoch [5/30]
Loss: 0.35835264121161564, Patience [0/3] (Best Loss: 0.35835264121161564)
Epoch [6/30]
Loss: 0.35835534218682186, Patience [1/3] (Best Loss: 0.35835264121161564)
Epoch [7/30]
Loss: 0.35835378778245713, Patience [2/3] (Best Loss: 0.35835264121161564)
Epoch [8/30]
Loss: 0.35835280386606855, Patience [3/3] (Best Loss: 0.35835264121161564)
Early stopping! Validation loss didn't improve in the last 3 epochs.
Start evaluate! Combination=(0, 2, 3, 4, 5)
Pearson correlation: nan
Elapsed Time: 209.7493770122528 seconds
Run with Hyperparams:
Number of Seqs: 15000, Batch_size: 64, Number of Epochs: 30, Learning Rate: 0.001, Weight Decay: 1e-05, Betas: (0.9, 0.999)
Load Data!
Loaded seqs file:  RBNS_training/RBP8_input.seq
Loaded seqs file:  RBNS_training/RBP8_5nM.seq
Loaded seqs file:  RBNS_training/RBP8_20nM.seq
Loaded seqs file:  RBNS_training/RBP8_80nM.seq
Loaded seqs file:  RBNS_training/RBP8_320nM.seq
Loaded seqs file:  RBNS_training/RBP8_1300nM.seq
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 512, 37]          16,896
              ReLU-2              [-1, 512, 37]               0
         MaxPool1d-3               [-1, 512, 7]               0
            Linear-4                   [-1, 64]         229,440
              ReLU-5                   [-1, 64]               0
           Dropout-6                   [-1, 64]               0
            Linear-7                   [-1, 32]           2,080
              ReLU-8                   [-1, 32]               0
           Dropout-9                   [-1, 32]               0
           Linear-10                   [-1, 32]           1,056
             ReLU-11                   [-1, 32]               0
          Dropout-12                   [-1, 32]               0
           Linear-13                    [-1, 6]             198
          Sigmoid-14                    [-1, 6]               0
================================================================
Total params: 249,670
Trainable params: 249,670
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.95
Estimated Total Size (MB): 1.27
----------------------------------------------------------------
Start Training!
Epoch [1/30]
Loss: 0.358369668451945, Patience [0/3] (Best Loss: 0.358369668451945)
Epoch [2/30]
Loss: 0.3583590107176039, Patience [0/3] (Best Loss: 0.3583590107176039)
Epoch [3/30]
Loss: 0.3583656748453776, Patience [1/3] (Best Loss: 0.3583590107176039)
Epoch [4/30]
Loss: 0.3583605625576443, Patience [2/3] (Best Loss: 0.3583590107176039)
Epoch [5/30]
Loss: 0.35835255415174694, Patience [0/3] (Best Loss: 0.35835255415174694)
Epoch [6/30]
Loss: 0.35836047253078884, Patience [1/3] (Best Loss: 0.35835255415174694)
Epoch [7/30]
Loss: 0.3583543433931139, Patience [2/3] (Best Loss: 0.35835255415174694)
Epoch [8/30]
Loss: 0.35835631658766004, Patience [3/3] (Best Loss: 0.35835255415174694)
Early stopping! Validation loss didn't improve in the last 3 epochs.
Start evaluate! Combination=(0, 2, 3, 4, 5)
Pearson correlation: 4.254518717061728e-05
Elapsed Time: 202.8438696861267 seconds
Run with Hyperparams:
Number of Seqs: 15000, Batch_size: 64, Number of Epochs: 30, Learning Rate: 0.001, Weight Decay: 1e-05, Betas: (0.9, 0.999)
Load Data!
Loaded seqs file:  RBNS_training/RBP9_input.seq
Loaded seqs file:  RBNS_training/RBP9_5nM.seq
Loaded seqs file:  RBNS_training/RBP9_20nM.seq
Loaded seqs file:  RBNS_training/RBP9_80nM.seq
Loaded seqs file:  RBNS_training/RBP9_320nM.seq
Loaded seqs file:  RBNS_training/RBP9_1300nM.seq
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 512, 37]          16,896
              ReLU-2              [-1, 512, 37]               0
         MaxPool1d-3               [-1, 512, 7]               0
            Linear-4                   [-1, 64]         229,440
              ReLU-5                   [-1, 64]               0
           Dropout-6                   [-1, 64]               0
            Linear-7                   [-1, 32]           2,080
              ReLU-8                   [-1, 32]               0
           Dropout-9                   [-1, 32]               0
           Linear-10                   [-1, 32]           1,056
             ReLU-11                   [-1, 32]               0
          Dropout-12                   [-1, 32]               0
           Linear-13                    [-1, 6]             198
          Sigmoid-14                    [-1, 6]               0
================================================================
Total params: 249,670
Trainable params: 249,670
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.95
Estimated Total Size (MB): 1.27
----------------------------------------------------------------
Start Training!
Epoch [1/30]
Loss: 0.358364869011773, Patience [0/3] (Best Loss: 0.358364869011773)
Epoch [2/30]
Loss: 0.358360241317749, Patience [0/3] (Best Loss: 0.358360241317749)
Epoch [3/30]
Loss: 0.35835766281551784, Patience [0/3] (Best Loss: 0.35835766281551784)
Epoch [4/30]
Loss: 0.3583609499189589, Patience [1/3] (Best Loss: 0.35835766281551784)
Epoch [5/30]
Loss: 0.3583621178097195, Patience [2/3] (Best Loss: 0.35835766281551784)
Epoch [6/30]
Loss: 0.3583587786356608, Patience [3/3] (Best Loss: 0.35835766281551784)
Early stopping! Validation loss didn't improve in the last 3 epochs.
Start evaluate! Combination=(0, 2, 3, 4, 5)
Pearson correlation: 0.16298571228981018
Elapsed Time: 178.37793850898743 seconds
Run with Hyperparams:
Number of Seqs: 15000, Batch_size: 64, Number of Epochs: 30, Learning Rate: 0.001, Weight Decay: 1e-05, Betas: (0.9, 0.999)
Load Data!
Loaded seqs file:  RBNS_training/RBP10_input.seq
Loaded seqs file:  RBNS_training/RBP10_5nM.seq
Loaded seqs file:  RBNS_training/RBP10_20nM.seq
Loaded seqs file:  RBNS_training/RBP10_80nM.seq
Loaded seqs file:  RBNS_training/RBP10_320nM.seq
Loaded seqs file:  RBNS_training/RBP10_1300nM.seq
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 512, 37]          16,896
              ReLU-2              [-1, 512, 37]               0
         MaxPool1d-3               [-1, 512, 7]               0
            Linear-4                   [-1, 64]         229,440
              ReLU-5                   [-1, 64]               0
           Dropout-6                   [-1, 64]               0
            Linear-7                   [-1, 32]           2,080
              ReLU-8                   [-1, 32]               0
           Dropout-9                   [-1, 32]               0
           Linear-10                   [-1, 32]           1,056
             ReLU-11                   [-1, 32]               0
          Dropout-12                   [-1, 32]               0
           Linear-13                    [-1, 6]             198
          Sigmoid-14                    [-1, 6]               0
================================================================
Total params: 249,670
Trainable params: 249,670
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.95
Estimated Total Size (MB): 1.27
----------------------------------------------------------------
Start Training!
Epoch [1/30]
Loss: 0.358365205722385, Patience [0/3] (Best Loss: 0.358365205722385)
Epoch [2/30]
Loss: 0.35837311848534475, Patience [1/3] (Best Loss: 0.358365205722385)
Epoch [3/30]
Loss: 0.3583617483562893, Patience [0/3] (Best Loss: 0.3583617483562893)
Epoch [4/30]
Loss: 0.35835688739352756, Patience [0/3] (Best Loss: 0.35835688739352756)
Epoch [5/30]
Loss: 0.35836432548099095, Patience [1/3] (Best Loss: 0.35835688739352756)
Epoch [6/30]
Loss: 0.3583521245320638, Patience [0/3] (Best Loss: 0.3583521245320638)
Epoch [7/30]
Loss: 0.35836067182752823, Patience [1/3] (Best Loss: 0.3583521245320638)
Epoch [8/30]
Loss: 0.3583646007537842, Patience [2/3] (Best Loss: 0.3583521245320638)
Epoch [9/30]
Loss: 0.35836180489857994, Patience [3/3] (Best Loss: 0.3583521245320638)
Early stopping! Validation loss didn't improve in the last 3 epochs.
Start evaluate! Combination=(0, 2, 3, 4, 5)
Pearson correlation: -0.01590476743876934
Elapsed Time: 228.30306005477905 seconds
-----------------------------------------------
-8.049221844608212e-10
0.25616076588630676
0.04411177709698677
-4.714014067985772e-09
4.2279886258711485e-08
0.014183035120368004
nan
4.254518717061728e-05
0.16298571228981018
-0.01590476743876934